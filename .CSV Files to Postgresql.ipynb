{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved Customers.csv to datasets\n",
      "Moved Orders.csv to datasets\n",
      "Moved Products.csv to datasets\n",
      "Moved Returns.csv to datasets\n",
      "Using ISO-8859-1 encoding for Customers.csv\n",
      "Using ISO-8859-1 encoding for Orders.csv\n",
      "Using ISO-8859-1 encoding for Products.csv\n",
      "Using ISO-8859-1 encoding for Returns.csv\n",
      "Opened the database successfully for customers\n",
      "customers was created successfully\n",
      "File Customers.csv opened in memory\n",
      "File Customers.csv copied to database\n",
      "Opened the database successfully for orders\n",
      "orders was created successfully\n",
      "File Orders.csv opened in memory\n",
      "File Orders.csv copied to database\n",
      "Opened the database successfully for products\n",
      "products was created successfully\n",
      "File Products.csv opened in memory\n",
      "File Products.csv copied to database\n",
      "Opened the database successfully for returns\n",
      "returns was created successfully\n",
      "File Returns.csv opened in memory\n",
      "File Returns.csv copied to database\n",
      "All tables have been successfully imported into the database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# Find CSV files in my current working directory\n",
    "csv_files = [file for file in os.listdir(os.getcwd()) if file.endswith('.csv')]\n",
    "\n",
    "# Create a new directory\n",
    "dataset_dir = 'datasets'\n",
    "try:\n",
    "    os.mkdir(dataset_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Move the CSV files to the new directory\n",
    "for csv in csv_files:\n",
    "    src_path = os.path.abspath(csv)\n",
    "    dest_path = os.path.join(dataset_dir, csv)\n",
    "    try:\n",
    "        shutil.move(src_path, dest_path)\n",
    "        print(f\"Moved {csv} to {dataset_dir}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {csv}\")\n",
    "    except shutil.Error as e:\n",
    "        print(f\"Error moving file {csv}: {e}\")\n",
    "\n",
    "# Read CSV files into Pandas DataFrames\n",
    "df = {}\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(dataset_dir, file)\n",
    "    try:\n",
    "        df[file] = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
    "        print(f\"Using ISO-8859-1 encoding for {file}\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Error decoding file {file}\")\n",
    "\n",
    "# Clean table names and column names\n",
    "for file, dataframe in df.items():\n",
    "    clean_table_name = file.lower().replace(\" \", \"_\").replace(\"?\", \"\") \\\n",
    "        .replace(\"-\", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\"%\", \"\") \\\n",
    "        .replace(\")\", \"\").replace(\"(\", \"\").replace(\"$\", \"\")\n",
    "\n",
    "# Remove .csv extension from clean_table_name\n",
    "    table_name = clean_table_name.split('.')[0]\n",
    "\n",
    "    dataframe.columns = [col.lower().replace(\" \", \"_\").replace(\"?\", \"\").replace(\"Â¢\", \"\") \\\n",
    "                         .replace(\"-\", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\"%\", \"\") \\\n",
    "                         .replace(\")\", \"\").replace(\"(\", \"\").replace(\"$\", \"\").replace(\".\", \"\")\n",
    "                         for col in dataframe.columns]\n",
    "\n",
    "   # Replacement dictionary that maps pandas datatypes to PostgreSQL datatypes\n",
    "    replacements = {\n",
    "    'object': 'varchar',\n",
    "    'float64': 'double precision',\n",
    "    'float32': 'real',\n",
    "    'int64': 'bigint',\n",
    "    'int32': 'integer',\n",
    "    'int16': 'smallint',\n",
    "    'timedelta64[ns]': 'varchar',\n",
    "    'timedelta64': 'interval',\n",
    "    'datetime64[ns]': 'timestamp',\n",
    "    'bool': 'boolean',\n",
    "    'datetime64': 'timestamp'}\n",
    "    \n",
    "    # Table Schema\n",
    "    col_str = \", \".join(\"{} {}\".format(n, replacements.get(str(d), 'varchar')) for (n, d) in\n",
    "                        zip(dataframe.columns, dataframe.dtypes))\n",
    "\n",
    "    # Open a database connection\n",
    "    hostname = 'localhost'\n",
    "    database = 'globalsuperstore'\n",
    "    username = 'postgres'\n",
    "    password = 'password'\n",
    "    port_id = 5432\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=hostname,\n",
    "        dbname=database,\n",
    "        user=username,\n",
    "        password=password,\n",
    "        port=port_id\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    print(f'Opened the database successfully for {table_name}')\n",
    "\n",
    "    # Drop table with same name\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
    "    \n",
    "    # Create SQL table\n",
    "    cursor.execute(f\"CREATE TABLE {table_name} ({col_str});\")\n",
    "    print(f'{table_name} was created successfully')\n",
    "\n",
    "    # Save dataframe to csv file\n",
    "    dataframe.to_csv(file, header=dataframe.columns, index=False, encoding='utf-8')\n",
    "\n",
    "    # Open csv file,save it as an object\n",
    "    with open(file) as my_file:\n",
    "        print(f'File {file} opened in memory')\n",
    "        \n",
    "    # Upload to database    \n",
    "        cursor.copy_expert(sql=f\"COPY {table_name} FROM STDIN WITH CSV HEADER DELIMITER AS ',';\", file=my_file)\n",
    "        print(f'File {file} copied to database')\n",
    "\n",
    "    # Open permission for any user that access the database\n",
    "    cursor.execute(f\"GRANT SELECT ON TABLE {table_name} TO public;\")\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# For loop end message\n",
    "print('All tables have been successfully imported into the database.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
