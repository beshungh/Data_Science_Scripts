{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved Original dataset.xlsx to datasets\n",
      "Reading Original dataset.xlsx\n",
      "Opened the database successfully for original_dataset\n",
      "original_dataset was created successfully\n",
      "File Original dataset.xlsx opened in memory\n",
      "File Original dataset.xlsx copied to database\n",
      "All tables have been successfully imported into the database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# Find Excel files in the current directory\n",
    "excel_files = [file for file in os.listdir(os.getcwd()) if file.endswith('.xlsx')]\n",
    "\n",
    "# Create a new directory\n",
    "dataset_dir = 'datasets'\n",
    "try:\n",
    "    os.mkdir(dataset_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Move the Excel files to the new directory\n",
    "for excel in excel_files:\n",
    "    src_path = os.path.abspath(excel)\n",
    "    dest_path = os.path.join(dataset_dir, excel)\n",
    "    try:\n",
    "        shutil.move(src_path, dest_path)\n",
    "        print(f\"Moved {excel} to {dataset_dir}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {excel}\")\n",
    "    except shutil.Error as e:\n",
    "        print(f\"Error moving file {excel}: {e}\")\n",
    "\n",
    "# Read Excel files into Pandas DataFrames\n",
    "df = {}\n",
    "for file in excel_files:\n",
    "    file_path = os.path.join(dataset_dir, file)\n",
    "    try:\n",
    "        df[file] = pd.read_excel(file_path)\n",
    "        print(f\"Reading {file}\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error parsing file {file}\")\n",
    "\n",
    "# Iterate over DataFrames, clean column names, and upload to PostgreSQL\n",
    "replacements = {\n",
    "    'object': 'varchar',\n",
    "    'float64': 'float',\n",
    "    'int64': 'bigint',\n",
    "    'timedelta64[ns]': 'varchar',\n",
    "    'datetime64[ns]': 'timestamp',\n",
    "    'bool': 'boolean',\n",
    "    'datetime64': 'timestamp'\n",
    "}\n",
    "\n",
    "hostname = 'localhost'\n",
    "database = 'covid19'\n",
    "username = 'postgres'\n",
    "password = 'password'\n",
    "port_id = 5432\n",
    "\n",
    "for file, dataframe in df.items():\n",
    "    clean_table_name = file.lower().replace(\" \", \"_\").replace(\"?\", \"\") \\\n",
    "        .replace(\"-\", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\"%\", \"\") \\\n",
    "        .replace(\")\", \"\").replace(\"(\", \"\").replace(\"$\", \"\")\n",
    "\n",
    "    table_name = clean_table_name.split('.')[0]\n",
    "\n",
    "    dataframe.columns = [col.lower().replace(\" \", \"_\").replace(\"?\", \"\").replace(\"Â¢\", \"\") \\\n",
    "                         .replace(\"-\", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\"%\", \"\") \\\n",
    "                         .replace(\")\", \"\").replace(\"(\", \"\").replace(\"$\", \"\").replace(\".\", \"\")\n",
    "                         for col in dataframe.columns]\n",
    "\n",
    "    col_str = \", \".join(\"{} {}\".format(n, replacements.get(str(d), 'varchar')) for (n, d) in\n",
    "                        zip(dataframe.columns, dataframe.dtypes))\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        host=hostname,\n",
    "        dbname=database,\n",
    "        user=username,\n",
    "        password=password,\n",
    "        port=port_id\n",
    "    )\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    print(f'Opened the database successfully for {table_name}')\n",
    "\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
    "    cursor.execute(f\"CREATE TABLE {table_name} ({col_str});\")\n",
    "\n",
    "    print(f'{table_name} was created successfully')\n",
    "\n",
    "    dataframe.to_csv(file, header=dataframe.columns, index=False, encoding='utf-8')\n",
    "\n",
    "    with open(file) as my_file:\n",
    "        print(f'File {file} opened in memory')\n",
    "        cursor.copy_expert(sql=f\"COPY {table_name} FROM STDIN WITH CSV HEADER DELIMITER AS ',';\", file=my_file)\n",
    "        print(f'File {file} copied to database')\n",
    "\n",
    "    cursor.execute(f\"GRANT SELECT ON TABLE {table_name} TO public;\")\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "print('All tables have been successfully imported into the database.')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
